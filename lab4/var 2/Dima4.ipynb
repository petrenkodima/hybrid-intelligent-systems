{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m_r-GRqutT-"
      },
      "source": [
        "## https://public.roboflow.com/object-detection/aquarium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDKZBYFZaD7k",
        "outputId": "5590dabc-8ff3-4051-bacb-5bb2298013b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41 kB 231 kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 3.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 178 kB 58.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 145 kB 52.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54 kB 2.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 138 kB 46.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62 kB 751 kB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=ultralytics\n"
          ]
        }
      ],
      "source": [
        "%pip install -q roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnFNoRkLaULk",
        "outputId": "2e76c07a-6664-4d8f-ad90-7907e22912ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in American-Sign-Language-Letters-1 to yolov5pytorch: 100% [749434688 / 749434688] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to American-Sign-Language-Letters-1 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1451/1451 [00:04<00:00, 327.96it/s]\n"
          ]
        }
      ],
      "source": [
        "rf = Roboflow(api_key=\"CN6Rq0i5m4BC7aksBjV4\")\n",
        "project = rf.workspace().project(\"american-sign-language-letters-iskcl\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jDk-uCabHT8",
        "outputId": "48f27bdf-264f-4374-eb69-e73dd76e522a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14302, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 14302 (delta 26), reused 30 (delta 15), pack-reused 14246\u001b[K\n",
            "Receiving objects: 100% (14302/14302), 13.62 MiB | 30.06 MiB/s, done.\n",
            "Resolving deltas: 100% (9836/9836), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 182 kB 30.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62 kB 1.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.6 MB 48.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%rm -rf ../yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTCwS7fwbQPT",
        "outputId": "aa4ce243-1291-453a-ba8b-b62ec8e34745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=American-Sign-Language-Letters-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-18-gd7955fe Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 117MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 174MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=26\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     83607  models.yolo.Detect                      [26, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7089751 parameters, 7089751 gradients, 16.2 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/American-Sign-Language-Letters-1/train/labels... 504 images, 0 backgrounds, 0 corrupt: 100% 504/504 [00:00<00:00, 2148.82it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/American-Sign-Language-Letters-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100% 504/504 [01:02<00:00,  8.02it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/American-Sign-Language-Letters-1/valid/labels... 144 images, 0 backgrounds, 0 corrupt: 100% 144/144 [00:00<00:00, 689.90it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/American-Sign-Language-Letters-1/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 144/144 [00:24<00:00,  5.81it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.52 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99       1.7G    0.09926    0.02276    0.08832         24        416: 100% 32/32 [00:08<00:00,  3.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.57it/s]\n",
            "                   all        144        144    0.00213       0.51    0.00403    0.00119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99       1.9G    0.06202    0.02458     0.0824         17        416: 100% 32/32 [00:04<00:00,  6.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.38it/s]\n",
            "                   all        144        144    0.00884       0.32     0.0262    0.00626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99       1.9G    0.05722    0.02155    0.08001         22        416: 100% 32/32 [00:04<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.98it/s]\n",
            "                   all        144        144    0.00413       0.99     0.0882     0.0328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99       1.9G    0.05194    0.01887    0.07861         19        416: 100% 32/32 [00:04<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.73it/s]\n",
            "                   all        144        144      0.514       0.16      0.142     0.0597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99       1.9G    0.04568    0.01663    0.07759         17        416: 100% 32/32 [00:04<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.04it/s]\n",
            "                   all        144        144      0.117       0.45      0.158      0.075\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99       1.9G     0.0411    0.01511    0.07589         19        416: 100% 32/32 [00:04<00:00,  6.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.00it/s]\n",
            "                   all        144        144      0.191      0.332      0.176     0.0901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99       1.9G    0.03847    0.01377     0.0753         19        416: 100% 32/32 [00:05<00:00,  6.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.50it/s]\n",
            "                   all        144        144      0.215       0.45      0.168     0.0721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99       1.9G     0.0351      0.013     0.0735         16        416: 100% 32/32 [00:05<00:00,  5.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.25it/s]\n",
            "                   all        144        144      0.101      0.705      0.207      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99       1.9G    0.03546    0.01245    0.07311         17        416: 100% 32/32 [00:04<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.31it/s]\n",
            "                   all        144        144      0.313       0.39      0.189     0.0952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99       1.9G    0.03372    0.01219    0.07134         16        416: 100% 32/32 [00:04<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.05it/s]\n",
            "                   all        144        144      0.282      0.306      0.236      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99       1.9G    0.03108    0.01188    0.07105         27        416: 100% 32/32 [00:04<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.04it/s]\n",
            "                   all        144        144      0.454      0.296      0.247      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99       1.9G    0.03077    0.01129    0.06921         18        416: 100% 32/32 [00:04<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.98it/s]\n",
            "                   all        144        144      0.265      0.354      0.265      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99       1.9G    0.03067    0.01126    0.06829         22        416: 100% 32/32 [00:04<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.05it/s]\n",
            "                   all        144        144      0.472      0.273      0.262      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99       1.9G    0.02964    0.01123    0.06775         18        416: 100% 32/32 [00:04<00:00,  6.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.06it/s]\n",
            "                   all        144        144      0.456      0.379       0.31      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99       1.9G    0.02893    0.01104    0.06815         22        416: 100% 32/32 [00:04<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.10it/s]\n",
            "                   all        144        144      0.519      0.301      0.328      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99       1.9G    0.02955     0.0104    0.06662         19        416: 100% 32/32 [00:04<00:00,  6.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.11it/s]\n",
            "                   all        144        144      0.429      0.327      0.328      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99       1.9G    0.03016    0.01091    0.06538         21        416: 100% 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.99it/s]\n",
            "                   all        144        144      0.431      0.437      0.394      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99       1.9G     0.0286    0.01069    0.06455         18        416: 100% 32/32 [00:04<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.96it/s]\n",
            "                   all        144        144      0.411       0.53       0.39      0.294\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99       1.9G    0.02821   0.009716    0.06461         15        416: 100% 32/32 [00:04<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.17it/s]\n",
            "                   all        144        144      0.457      0.396      0.366      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99       1.9G    0.02776    0.01046    0.06309         17        416: 100% 32/32 [00:04<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.16it/s]\n",
            "                   all        144        144      0.383      0.504      0.402      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99       1.9G    0.02791    0.01033    0.06242         20        416: 100% 32/32 [00:04<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.07it/s]\n",
            "                   all        144        144      0.375      0.443      0.396      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99       1.9G    0.02617    0.01043    0.06161         14        416: 100% 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.94it/s]\n",
            "                   all        144        144      0.414       0.47      0.429       0.32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99       1.9G    0.02756    0.01054    0.05837         19        416: 100% 32/32 [00:04<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.94it/s]\n",
            "                   all        144        144      0.365      0.596      0.425      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99       1.9G    0.02721     0.0102    0.05965         12        416: 100% 32/32 [00:04<00:00,  6.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.11it/s]\n",
            "                   all        144        144      0.343      0.559      0.431      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99       1.9G    0.02655   0.009456    0.05725         13        416: 100% 32/32 [00:04<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.11it/s]\n",
            "                   all        144        144      0.372      0.562      0.454      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99       1.9G    0.02522   0.009671    0.05709         17        416: 100% 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.16it/s]\n",
            "                   all        144        144      0.327      0.609      0.463      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99       1.9G    0.02542   0.009728    0.05581         22        416: 100% 32/32 [00:04<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.06it/s]\n",
            "                   all        144        144      0.404      0.625      0.506      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99       1.9G    0.02498    0.01013    0.05636         16        416: 100% 32/32 [00:04<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.21it/s]\n",
            "                   all        144        144      0.363       0.65      0.533      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99       1.9G    0.02513   0.009776    0.05525         23        416: 100% 32/32 [00:04<00:00,  6.81it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.17it/s]\n",
            "                   all        144        144      0.403      0.587      0.529      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99       1.9G    0.02489   0.009439    0.05522         18        416: 100% 32/32 [00:04<00:00,  6.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.21it/s]\n",
            "                   all        144        144      0.382      0.691      0.576      0.414\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99       1.9G    0.02545    0.01037    0.05637         27        416: 100% 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.12it/s]\n",
            "                   all        144        144      0.424      0.606      0.574      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99       1.9G    0.02327   0.009072    0.05428         16        416: 100% 32/32 [00:04<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.08it/s]\n",
            "                   all        144        144      0.426      0.665      0.613      0.476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99       1.9G    0.02493   0.009328    0.05373         16        416: 100% 32/32 [00:04<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.96it/s]\n",
            "                   all        144        144      0.383       0.65      0.592      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99       1.9G    0.02453   0.009357    0.05248         24        416: 100% 32/32 [00:04<00:00,  6.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.77it/s]\n",
            "                   all        144        144      0.465        0.6        0.6      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99       1.9G    0.02406   0.009342     0.0519         18        416: 100% 32/32 [00:04<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.00it/s]\n",
            "                   all        144        144      0.396      0.749      0.608      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99       1.9G    0.02359   0.009023    0.05233         15        416: 100% 32/32 [00:04<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.04it/s]\n",
            "                   all        144        144      0.417      0.705      0.619      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99       1.9G    0.02449    0.00946    0.05105         20        416: 100% 32/32 [00:04<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.18it/s]\n",
            "                   all        144        144      0.386       0.74      0.644      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99       1.9G    0.02314   0.008917    0.04815         18        416: 100% 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.96it/s]\n",
            "                   all        144        144      0.537      0.615       0.65      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99       1.9G    0.02348   0.009536    0.04871         18        416: 100% 32/32 [00:04<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.12it/s]\n",
            "                   all        144        144      0.399       0.76      0.667      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99       1.9G    0.02309   0.009159    0.04859         21        416: 100% 32/32 [00:04<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.21it/s]\n",
            "                   all        144        144      0.526       0.61      0.669      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99       1.9G    0.02217   0.008963    0.04609         24        416: 100% 32/32 [00:04<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.15it/s]\n",
            "                   all        144        144       0.77      0.494      0.673      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99       1.9G    0.02377   0.009724    0.04618         16        416: 100% 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.06it/s]\n",
            "                   all        144        144      0.505      0.713      0.711      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99       1.9G    0.02325   0.008948    0.04645         22        416: 100% 32/32 [00:04<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.78it/s]\n",
            "                   all        144        144       0.54      0.639      0.701       0.57\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99       1.9G    0.02263   0.008491    0.04258         16        416: 100% 32/32 [00:04<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.14it/s]\n",
            "                   all        144        144      0.569       0.67      0.708      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99       1.9G      0.023    0.00908     0.0439         13        416: 100% 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.14it/s]\n",
            "                   all        144        144      0.598      0.696      0.741      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99       1.9G     0.0225    0.00836    0.04102         15        416: 100% 32/32 [00:04<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.98it/s]\n",
            "                   all        144        144      0.619      0.678      0.745      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99       1.9G    0.02336   0.009115    0.04336         23        416: 100% 32/32 [00:05<00:00,  5.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.24it/s]\n",
            "                   all        144        144      0.637      0.726      0.758      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99       1.9G    0.02306   0.008849    0.04428         22        416: 100% 32/32 [00:04<00:00,  6.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.89it/s]\n",
            "                   all        144        144      0.446      0.772      0.755      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99       1.9G    0.02261   0.008925     0.0395         25        416: 100% 32/32 [00:04<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.99it/s]\n",
            "                   all        144        144      0.626      0.679      0.758      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99       1.9G    0.02267   0.008735    0.04103         25        416: 100% 32/32 [00:04<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.03it/s]\n",
            "                   all        144        144      0.627      0.744      0.775      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99       1.9G    0.02154   0.008584    0.04103         19        416: 100% 32/32 [00:04<00:00,  6.81it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.08it/s]\n",
            "                   all        144        144      0.629      0.783       0.79       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99       1.9G    0.02236   0.008613    0.03887         18        416: 100% 32/32 [00:04<00:00,  6.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.03it/s]\n",
            "                   all        144        144      0.633      0.758      0.788      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99       1.9G    0.02206   0.008701    0.03923         13        416: 100% 32/32 [00:04<00:00,  6.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.83it/s]\n",
            "                   all        144        144      0.576      0.848      0.781      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99       1.9G     0.0219   0.008531    0.03949         17        416: 100% 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.16it/s]\n",
            "                   all        144        144      0.597      0.807       0.78      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99       1.9G    0.02176   0.008946    0.03835         16        416: 100% 32/32 [00:04<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.08it/s]\n",
            "                   all        144        144      0.605      0.787      0.795      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99       1.9G    0.02076   0.008945    0.03871         17        416: 100% 32/32 [00:04<00:00,  6.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.02it/s]\n",
            "                   all        144        144      0.603      0.805       0.81      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99       1.9G    0.02061   0.008696    0.03651         20        416: 100% 32/32 [00:04<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.06it/s]\n",
            "                   all        144        144      0.609      0.851      0.818      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99       1.9G    0.02148   0.008637    0.03672         19        416: 100% 32/32 [00:04<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.04it/s]\n",
            "                   all        144        144      0.583      0.851      0.829      0.717\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99       1.9G    0.02135   0.008721    0.03699         21        416: 100% 32/32 [00:04<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.16it/s]\n",
            "                   all        144        144      0.592      0.858        0.8      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99       1.9G    0.02091   0.008334    0.03474         17        416: 100% 32/32 [00:04<00:00,  6.81it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.09it/s]\n",
            "                   all        144        144      0.672      0.831      0.822      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99       1.9G     0.0203   0.008888    0.03519         18        416: 100% 32/32 [00:04<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.97it/s]\n",
            "                   all        144        144      0.634      0.843      0.828      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99       1.9G    0.01923   0.008309    0.03393         22        416: 100% 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.05it/s]\n",
            "                   all        144        144      0.603      0.826      0.836      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99       1.9G    0.02015     0.0085    0.03475         26        416: 100% 32/32 [00:04<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.94it/s]\n",
            "                   all        144        144      0.579      0.878      0.837      0.717\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99       1.9G    0.02006   0.007889    0.03427         19        416: 100% 32/32 [00:04<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.02it/s]\n",
            "                   all        144        144      0.612      0.879      0.845      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99       1.9G    0.01967   0.007995    0.03261         22        416: 100% 32/32 [00:04<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.02it/s]\n",
            "                   all        144        144      0.626      0.886      0.844      0.747\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99       1.9G    0.01974   0.008175    0.03184         16        416: 100% 32/32 [00:04<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.97it/s]\n",
            "                   all        144        144      0.656      0.857      0.847      0.716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99       1.9G    0.01941   0.008022    0.03166         17        416: 100% 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.15it/s]\n",
            "                   all        144        144      0.669      0.871      0.858      0.716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99       1.9G    0.01887   0.008179    0.03199         19        416: 100% 32/32 [00:04<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.15it/s]\n",
            "                   all        144        144      0.651      0.851       0.87      0.741\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99       1.9G    0.01955   0.008612    0.03131         17        416: 100% 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.12it/s]\n",
            "                   all        144        144      0.664      0.877      0.875      0.766\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99       1.9G    0.01917   0.008119    0.03058         14        416: 100% 32/32 [00:04<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.95it/s]\n",
            "                   all        144        144      0.621      0.887      0.859      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99       1.9G    0.01862   0.008269    0.02947         23        416: 100% 32/32 [00:04<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.26it/s]\n",
            "                   all        144        144      0.706      0.809      0.888      0.767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99       1.9G    0.01945   0.007853    0.03045         15        416: 100% 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.23it/s]\n",
            "                   all        144        144      0.684      0.853      0.882      0.764\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99       1.9G    0.01873   0.007853    0.02945         16        416: 100% 32/32 [00:04<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.12it/s]\n",
            "                   all        144        144       0.67        0.9      0.876      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99       1.9G    0.01857   0.007806    0.02787         20        416: 100% 32/32 [00:04<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.97it/s]\n",
            "                   all        144        144       0.68      0.885      0.882      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99       1.9G    0.01846   0.007728    0.02866         24        416: 100% 32/32 [00:04<00:00,  6.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.84it/s]\n",
            "                   all        144        144      0.662      0.886      0.873      0.777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99       1.9G    0.01822   0.007965    0.02863         21        416: 100% 32/32 [00:04<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.96it/s]\n",
            "                   all        144        144      0.667      0.889      0.886      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99       1.9G    0.01863   0.008188    0.02962         19        416: 100% 32/32 [00:04<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.04it/s]\n",
            "                   all        144        144      0.702        0.9      0.884      0.786\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99       1.9G     0.0173   0.007764    0.02807         21        416: 100% 32/32 [00:04<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.99it/s]\n",
            "                   all        144        144      0.703      0.891      0.885      0.789\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99       1.9G    0.01803    0.00809    0.02763         18        416: 100% 32/32 [00:04<00:00,  6.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.10it/s]\n",
            "                   all        144        144      0.714      0.879      0.899      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99       1.9G     0.0171   0.007312     0.0268         22        416: 100% 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.08it/s]\n",
            "                   all        144        144      0.701      0.898      0.902      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99       1.9G    0.01723   0.007781    0.02726         23        416: 100% 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.05it/s]\n",
            "                   all        144        144       0.69       0.87      0.894      0.794\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99       1.9G    0.01659   0.007705    0.02807         20        416: 100% 32/32 [00:04<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.95it/s]\n",
            "                   all        144        144      0.706      0.876      0.878      0.781\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99       1.9G    0.01681   0.007712    0.02751         12        416: 100% 32/32 [00:04<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.01it/s]\n",
            "                   all        144        144      0.712      0.869      0.885      0.793\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99       1.9G    0.01711   0.007369    0.02689         16        416: 100% 32/32 [00:04<00:00,  6.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.13it/s]\n",
            "                   all        144        144      0.727      0.847      0.881      0.783\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99       1.9G    0.01671   0.007598    0.02565         21        416: 100% 32/32 [00:04<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.01it/s]\n",
            "                   all        144        144      0.722      0.907      0.901      0.823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99       1.9G    0.01633   0.007818    0.02484         20        416: 100% 32/32 [00:04<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.99it/s]\n",
            "                   all        144        144      0.757      0.897      0.914       0.83\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99       1.9G    0.01565   0.007504    0.02527         14        416: 100% 32/32 [00:06<00:00,  5.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.62it/s]\n",
            "                   all        144        144      0.773       0.91      0.913      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99       1.9G    0.01569   0.007576    0.02509         22        416: 100% 32/32 [00:05<00:00,  6.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.97it/s]\n",
            "                   all        144        144      0.745      0.881      0.894      0.815\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99       1.9G    0.01549   0.007491    0.02445         24        416: 100% 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.17it/s]\n",
            "                   all        144        144      0.734      0.879      0.889      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99       1.9G    0.01542   0.007201    0.02452         22        416: 100% 32/32 [00:04<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.15it/s]\n",
            "                   all        144        144      0.757      0.903      0.902      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99       1.9G    0.01568   0.007348    0.02324         15        416: 100% 32/32 [00:04<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.06it/s]\n",
            "                   all        144        144      0.749      0.895      0.904      0.818\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99       1.9G    0.01516   0.007457    0.02275         20        416: 100% 32/32 [00:04<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.04it/s]\n",
            "                   all        144        144      0.746      0.883      0.897       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99       1.9G    0.01496   0.007421    0.02284         17        416: 100% 32/32 [00:04<00:00,  6.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.04it/s]\n",
            "                   all        144        144      0.751      0.873      0.904      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99       1.9G    0.01497   0.007406    0.02302         19        416: 100% 32/32 [00:04<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.99it/s]\n",
            "                   all        144        144      0.733      0.885      0.901      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99       1.9G     0.0145   0.007261     0.0212         16        416: 100% 32/32 [00:04<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.96it/s]\n",
            "                   all        144        144      0.762      0.888      0.917      0.842\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99       1.9G    0.01453   0.007537    0.02348         17        416: 100% 32/32 [00:04<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  5.88it/s]\n",
            "                   all        144        144      0.769      0.897      0.913      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99       1.9G    0.01453    0.00716    0.02292         15        416: 100% 32/32 [00:04<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.10it/s]\n",
            "                   all        144        144       0.78      0.899      0.915      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99       1.9G    0.01327   0.007049    0.02049         20        416: 100% 32/32 [00:04<00:00,  6.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.16it/s]\n",
            "                   all        144        144      0.784       0.92      0.914      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99       1.9G    0.01381   0.006514    0.02097         16        416: 100% 32/32 [00:04<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.12it/s]\n",
            "                   all        144        144      0.776      0.904      0.917      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99       1.9G    0.01367    0.00707    0.01962         21        416: 100% 32/32 [00:04<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:00<00:00,  6.06it/s]\n",
            "                   all        144        144      0.775      0.906      0.916      0.843\n",
            "\n",
            "100 epochs completed in 0.171 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7080247 parameters, 0 gradients, 16.0 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.47it/s]\n",
            "                   all        144        144      0.777        0.9      0.916      0.846\n",
            "                     A        144          5      0.519        0.8      0.895      0.885\n",
            "                     B        144          9          1      0.835      0.995      0.906\n",
            "                     C        144          3      0.874          1      0.995      0.912\n",
            "                     D        144          6      0.737      0.833      0.942      0.836\n",
            "                     E        144          4      0.716          1      0.995      0.995\n",
            "                     F        144          8      0.882      0.935      0.982      0.982\n",
            "                     G        144          5      0.764          1      0.995        0.9\n",
            "                     H        144          9          1      0.993      0.995      0.953\n",
            "                     I        144          2      0.315        0.5      0.509      0.458\n",
            "                     J        144          8      0.933          1      0.995      0.738\n",
            "                     K        144          6          1      0.935      0.995      0.933\n",
            "                     L        144          4      0.613          1      0.945      0.892\n",
            "                     M        144          8      0.746      0.875      0.831      0.748\n",
            "                     N        144          4      0.324       0.75      0.518      0.468\n",
            "                     O        144          7          1      0.896      0.995      0.937\n",
            "                     P        144          7      0.937          1      0.995      0.842\n",
            "                     Q        144          4      0.898          1      0.995      0.879\n",
            "                     R        144          7      0.925          1      0.995      0.961\n",
            "                     S        144          4        0.9          1      0.995      0.995\n",
            "                     T        144          6      0.819      0.759      0.874      0.843\n",
            "                     U        144          7       0.79      0.857      0.953       0.87\n",
            "                     V        144          5      0.389        0.6      0.437      0.413\n",
            "                     W        144          3      0.571          1      0.995      0.929\n",
            "                     X        144          1      0.652          1      0.995      0.895\n",
            "                     Y        144          8          1      0.828      0.995      0.886\n",
            "                     Z        144          4      0.887          1      0.995      0.937\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train.py --img 416 --batch 16 --epochs 100 --data American-Sign-Language-Letters-1/data.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsGmHNO-jjbF",
        "outputId": "c5b1b2b9-2bac-4c2a-c208-aa42cf2c7808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=American-Sign-Language-Letters-1/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-18-gd7955fe Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7080247 parameters, 0 gradients, 16.0 GFLOPs\n",
            "image 1/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/A22_jpg.rf.c8f3c81ea49db2c7846760dca1de6dba.jpg: 416x320 1 A, 11.4ms\n",
            "image 2/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/B14_jpg.rf.b224afc059db380d71077e7cc90883ba.jpg: 416x320 1 B, 7.9ms\n",
            "image 3/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/B15_jpg.rf.6fe73096064f5a6a149741a894c6a4a2.jpg: 416x320 1 B, 8.1ms\n",
            "image 4/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/B19_jpg.rf.dfc0120bf7a43e93355549dfd18eb8d6.jpg: 416x320 1 B, 8.0ms\n",
            "image 5/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/C17_jpg.rf.ef1d1eba40c7fedec49bb61ec8515f3c.jpg: 416x320 1 C, 8.0ms\n",
            "image 6/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/C19_jpg.rf.bbd5e09aaf3345fcc2a18d329d01e4fc.jpg: 416x320 1 F, 7.8ms\n",
            "image 7/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/C22_jpg.rf.e1923697a9ec8841eca8bb6fa3213e69.jpg: 416x320 1 C, 8.3ms\n",
            "image 8/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/C23_jpg.rf.bf957dc96789b73ce6e4c1c905f83cb5.jpg: 416x320 1 C, 7.7ms\n",
            "image 9/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/D1_jpg.rf.7db0aca5741f694ce1404076ee880cf0.jpg: 416x320 1 D, 7.8ms\n",
            "image 10/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/F17_jpg.rf.b3ad96b08bf905796455b320a662a360.jpg: 416x320 1 F, 8.0ms\n",
            "image 11/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/F3_jpg.rf.bcdcce2ca4e6c80fc27b2d6c0f9fcbf2.jpg: 416x320 1 F, 7.8ms\n",
            "image 12/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/G11_jpg.rf.e00603a26cd537177bbeaf7a2b7f6c09.jpg: 416x320 1 G, 7.8ms\n",
            "image 13/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/G20_jpg.rf.334d8d95c06e5fa8d14e317321cab4f1.jpg: 416x320 1 G, 7.7ms\n",
            "image 14/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/G3_jpg.rf.76dc86cad6aebc73fc9e6ae9b4a2a976.jpg: 416x320 1 G, 7.8ms\n",
            "image 15/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/G4_jpg.rf.43d0951c97fb90f8736a79fbaa33ec1e.jpg: 416x320 1 G, 9.9ms\n",
            "image 16/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/G7_jpg.rf.f0b45ee5de7e037ca04a58993b0bb8bd.jpg: 416x320 1 G, 7.8ms\n",
            "image 17/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/H19_jpg.rf.31ba5f18a9ad38c0c69c801d2bff126b.jpg: 416x320 1 H, 8.0ms\n",
            "image 18/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/H25_jpg.rf.4ab83f9b8512e0b28fa303ad5d19b7cf.jpg: 416x320 1 H, 9.6ms\n",
            "image 19/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/H5_jpg.rf.ba9629491fbd8c6d76d1d85d971091b9.jpg: 416x320 1 H, 7.9ms\n",
            "image 20/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/I17_jpg.rf.73f4840a656e62734a73486f9b888865.jpg: 416x320 1 I, 7.8ms\n",
            "image 21/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/I28_jpg.rf.6f2d9dfdef0c7ae5111df6f72b7c2f0e.jpg: 416x320 1 F, 8.3ms\n",
            "image 22/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/J27_jpg.rf.b78c3cf7363310155deaca32568fe789.jpg: 416x320 1 J, 7.8ms\n",
            "image 23/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/J28_jpg.rf.7695e55ab62959270a90d45f25e7a21c.jpg: 416x320 1 J, 8.5ms\n",
            "image 24/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/J6_jpg.rf.d5a92e742438616bc9592b1ddeb37a55.jpg: 416x320 1 J, 7.7ms\n",
            "image 25/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/J9_jpg.rf.5214dadb47f46eb9815bb8106cc5a069.jpg: 416x320 1 J, 8.4ms\n",
            "image 26/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/K12_jpg.rf.b2e8a98e27a24c30d6343398425ef429.jpg: 416x320 (no detections), 7.7ms\n",
            "image 27/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/K13_jpg.rf.305546ce0b2a2e5d4f587205ac1c93f8.jpg: 416x320 1 V, 7.8ms\n",
            "image 28/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/K24_jpg.rf.b23be99840a28a570096ec3c32ddaa8b.jpg: 416x320 1 K, 8.6ms\n",
            "image 29/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/K6_jpg.rf.23db96babd242c124ad698643e358fe6.jpg: 416x320 1 K, 11.6ms\n",
            "image 30/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/M14_jpg.rf.4a9784c033737d3bfc37cfc6def81dac.jpg: 416x320 1 M, 7.8ms\n",
            "image 31/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/M20_jpg.rf.ae289d97a7a9e1a96aa5c478376b6750.jpg: 416x320 1 A, 7.8ms\n",
            "image 32/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/M24_jpg.rf.6979fdba0c80cd7cd62877064675fd83.jpg: 416x320 1 M, 8.1ms\n",
            "image 33/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/N22_jpg.rf.4482b0257fe0682e261006a2ddf0fb6b.jpg: 416x320 1 N, 1 T, 7.9ms\n",
            "image 34/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/N6_jpg.rf.146cbf57f0920c853a709b8200b8342b.jpg: 416x320 1 N, 7.7ms\n",
            "image 35/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/N9_jpg.rf.d42236aff899b78d7a4416a81cce02cc.jpg: 416x320 1 A, 7.8ms\n",
            "image 36/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/O12_jpg.rf.5286fc64d3ca171277929214749d3a2d.jpg: 416x320 1 O, 7.9ms\n",
            "image 37/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/O20_jpg.rf.0d1489aa427c93a372992cb9d99dae45.jpg: 416x320 1 O, 8.1ms\n",
            "image 38/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/O4_jpg.rf.fa3e4584d61e5787b9048a730a3be1ec.jpg: 416x320 1 O, 8.2ms\n",
            "image 39/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/P24_jpg.rf.1f8b74c1279bb388c7f3250056d4cb9c.jpg: 416x320 1 P, 8.0ms\n",
            "image 40/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/Q10_jpg.rf.db1863d56cdbc75add596eba69c1f109.jpg: 416x320 1 Q, 8.2ms\n",
            "image 41/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/Q7_jpg.rf.3c31fa7791ee37966b2f5b4475044dff.jpg: 416x320 (no detections), 7.9ms\n",
            "image 42/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/R18_jpg.rf.04dc456a5cf42c48786353c585de0894.jpg: 416x320 1 R, 8.1ms\n",
            "image 43/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/R5_jpg.rf.24fca1cd8ae905459d8fbbc5901459da.jpg: 416x320 (no detections), 8.4ms\n",
            "image 44/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/S0_jpg.rf.9cb94162cd892be616da1c6e052c11ca.jpg: 416x320 1 O, 8.2ms\n",
            "image 45/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/S16_jpg.rf.17da267cc475581355233e0bfd5ed700.jpg: 416x320 1 S, 11.8ms\n",
            "image 46/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/S6_jpg.rf.31fd7c1969af3e8f8cff09d09436b5e7.jpg: 416x320 1 S, 7.9ms\n",
            "image 47/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/T13_jpg.rf.0aa78a2e2d57740e0f26e98adacc1e68.jpg: 416x320 1 N, 1 T, 7.7ms\n",
            "image 48/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/T17_jpg.rf.6e347003b7f2f590695a71a5ee7fa129.jpg: 416x320 1 N, 1 T, 8.0ms\n",
            "image 49/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/T18_jpg.rf.704840e1054b9e5cb4b19f2c06d98909.jpg: 416x320 1 N, 7.7ms\n",
            "image 50/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/T1_jpg.rf.8d148dde7aeec361a42fed93e6417876.jpg: 416x320 (no detections), 7.7ms\n",
            "image 51/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/T24_jpg.rf.4296062c071ab0681ec648c4bb175802.jpg: 416x320 1 N, 8.0ms\n",
            "image 52/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/U5_jpg.rf.7da444202e3445c1cee3c7c8291397f0.jpg: 416x320 (no detections), 8.2ms\n",
            "image 53/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/U6_jpg.rf.b6c44d968a1040619f0fb07e79d0d732.jpg: 416x320 1 U, 7.6ms\n",
            "image 54/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/V10_jpg.rf.97e4e465c27bc51cd9ec89039411206d.jpg: 416x320 1 V, 7.8ms\n",
            "image 55/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/V12_jpg.rf.c4ecffd29e53ac36ea3f49ff9468fb22.jpg: 416x320 1 V, 8.0ms\n",
            "image 56/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/V27_jpg.rf.8ad9e55e421839c98d2d45c9f230f206.jpg: 416x320 1 V, 8.1ms\n",
            "image 57/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/V2_jpg.rf.12328e875ada560f102fec4f9b1e9991.jpg: 416x320 1 K, 7.9ms\n",
            "image 58/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/W16_jpg.rf.90b65d0fe9441eed7ea915b81b4b844f.jpg: 416x320 1 W, 7.8ms\n",
            "image 59/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/W19_jpg.rf.a01f065f60ad8dd34df5652ffb777250.jpg: 416x320 1 W, 7.8ms\n",
            "image 60/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/W23_jpg.rf.b202083db38d1e70def6291c8f808472.jpg: 416x320 1 W, 8.3ms\n",
            "image 61/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/W24_jpg.rf.df2e0b536634961052856f8ab1988f95.jpg: 416x320 1 W, 7.9ms\n",
            "image 62/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/W7_jpg.rf.25f3f4d2ea1e53b2627b1010f3b4ccc8.jpg: 416x320 1 W, 8.0ms\n",
            "image 63/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/X14_jpg.rf.6d9394dca25946228577b2f291d4f92f.jpg: 416x320 1 X, 9.1ms\n",
            "image 64/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/X20_jpg.rf.9543ed777d75027f0e3acec050c0a9a7.jpg: 416x320 1 X, 7.9ms\n",
            "image 65/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/X24_jpg.rf.dae285778673239fd9e1d9591301f7a1.jpg: 416x320 1 X, 8.0ms\n",
            "image 66/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/X9_jpg.rf.ac175659e68bf69b3d645e5f66ef2451.jpg: 416x320 1 X, 7.9ms\n",
            "image 67/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/Y25_jpg.rf.cb5959b9505561a4ea636f5b35916b27.jpg: 416x320 1 Y, 8.1ms\n",
            "image 68/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/Y5_jpg.rf.5aa85d73b09e11d0e823ad805b56e939.jpg: 416x320 1 Y, 8.3ms\n",
            "image 69/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/Z16_jpg.rf.ce0e03437c53cd109b45edc0201b2859.jpg: 416x320 1 Z, 7.8ms\n",
            "image 70/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/Z18_jpg.rf.b541e5a411a7fefa5b74e668fa33a714.jpg: 416x320 1 Z, 8.1ms\n",
            "image 71/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/Z27_jpg.rf.956c5ede911f763bd8bb1194a6029775.jpg: 416x320 1 Z, 8.1ms\n",
            "image 72/72 /content/yolov5/American-Sign-Language-Letters-1/test/images/Z9_jpg.rf.cdcb3e971e7eff9eca1f69831f9cc007.jpg: 416x320 1 Z, 8.4ms\n",
            "Speed: 0.4ms pre-process, 8.2ms inference, 1.0ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n",
            "67 labels saved to runs/detect/exp/labels\n"
          ]
        }
      ],
      "source": [
        "train_n = ''\n",
        "\n",
        "!python detect.py --weights runs/train/exp{train_n}/weights/best.pt --img 416 --save-txt --conf 0.5 --source American-Sign-Language-Letters-1/test/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "881olUjIlz_Z"
      },
      "outputs": [],
      "source": [
        "classes = { 0: 'A',\n",
        "            1: 'B',\n",
        "            2: 'C',\n",
        "            3: 'D',\n",
        "            4: 'E',\n",
        "            5: 'F',\n",
        "            6: 'G',\n",
        "            7: 'H',\n",
        "            8: 'I',\n",
        "            9: 'J',\n",
        "            10: 'K',\n",
        "            11: 'L',\n",
        "            12: 'M',\n",
        "            13: 'N',\n",
        "            14: 'O',\n",
        "            15: 'P',\n",
        "            16: 'Q',\n",
        "            17: 'R',\n",
        "            18: 'S',\n",
        "            19: 'T',\n",
        "            20: 'U',\n",
        "            21: 'V',\n",
        "            22: 'W',\n",
        "            23: 'X',\n",
        "            24: 'Y',\n",
        "            25: 'Z' }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UkJPAFPjl0oY",
        "outputId": "d70f6d8b-c449-48b1-89b4-ffae930f7f28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                objects\n",
              "K24_jpg.rf.b23be99840a28a570096ec3c32ddaa8b.jpg     [K]\n",
              "N6_jpg.rf.146cbf57f0920c853a709b8200b8342b.jpg      [N]\n",
              "Z9_jpg.rf.cdcb3e971e7eff9eca1f69831f9cc007.jpg      [Z]\n",
              "X20_jpg.rf.9543ed777d75027f0e3acec050c0a9a7.jpg     [X]\n",
              "J27_jpg.rf.b78c3cf7363310155deaca32568fe789.jpg     [J]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad5ef504-5008-42c5-bea0-c06d84c7b1fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>objects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>K24_jpg.rf.b23be99840a28a570096ec3c32ddaa8b.jpg</th>\n",
              "      <td>[K]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N6_jpg.rf.146cbf57f0920c853a709b8200b8342b.jpg</th>\n",
              "      <td>[N]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Z9_jpg.rf.cdcb3e971e7eff9eca1f69831f9cc007.jpg</th>\n",
              "      <td>[Z]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X20_jpg.rf.9543ed777d75027f0e3acec050c0a9a7.jpg</th>\n",
              "      <td>[X]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>J27_jpg.rf.b78c3cf7363310155deaca32568fe789.jpg</th>\n",
              "      <td>[J]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad5ef504-5008-42c5-bea0-c06d84c7b1fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad5ef504-5008-42c5-bea0-c06d84c7b1fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad5ef504-5008-42c5-bea0-c06d84c7b1fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "df = pd.DataFrame(columns=[\"objects\"])\n",
        "\n",
        "det_n = ''\n",
        "dir = f\"runs/detect/exp{det_n}/labels\"\n",
        "for filename in os.listdir(dir):\n",
        "  with open(os.path.join(dir, filename), \"r\") as f:\n",
        "    text = f.readlines()\n",
        "    objects = []\n",
        "    for i in text:\n",
        "      label = int(i.split(' ')[0])\n",
        "      objects.append(classes[label])\n",
        "      index = filename[:-3]+\"jpg\"\n",
        "      df.loc[index, 'objects'] = objects\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eCh-Yytbm7jP"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"/content/result.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q38b7-A0nK-W",
        "outputId": "c81ab539-fad9-49a0-ae18-173bc5919a47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 67 entries, K24_jpg.rf.b23be99840a28a570096ec3c32ddaa8b.jpg to I28_jpg.rf.6f2d9dfdef0c7ae5111df6f72b7c2f0e.jpg\n",
            "Data columns (total 26 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   A       67 non-null     bool \n",
            " 1   B       67 non-null     bool \n",
            " 2   C       67 non-null     bool \n",
            " 3   D       67 non-null     bool \n",
            " 4   E       67 non-null     bool \n",
            " 5   F       67 non-null     bool \n",
            " 6   G       67 non-null     bool \n",
            " 7   H       67 non-null     bool \n",
            " 8   I       67 non-null     bool \n",
            " 9   J       67 non-null     bool \n",
            " 10  K       67 non-null     bool \n",
            " 11  L       67 non-null     bool \n",
            " 12  M       67 non-null     bool \n",
            " 13  N       67 non-null     bool \n",
            " 14  O       67 non-null     bool \n",
            " 15  P       67 non-null     bool \n",
            " 16  Q       67 non-null     bool \n",
            " 17  R       67 non-null     bool \n",
            " 18  S       67 non-null     bool \n",
            " 19  T       67 non-null     bool \n",
            " 20  U       67 non-null     bool \n",
            " 21  V       67 non-null     bool \n",
            " 22  W       67 non-null     bool \n",
            " 23  X       67 non-null     bool \n",
            " 24  Y       67 non-null     bool \n",
            " 25  Z       67 non-null     bool \n",
            "dtypes: bool(26)\n",
            "memory usage: 4.3+ KB\n"
          ]
        }
      ],
      "source": [
        "def encode(image, objects):\n",
        "  for x in objects:\n",
        "    data.loc[image, x] = True\n",
        "\n",
        "data = pd.DataFrame(index = df.index, columns = classes.values())\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  encode(index, row['objects'])\n",
        "data = data.fillna(False)\n",
        "\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Yd-K2-MhoETB",
        "outputId": "8d207b0c-71c9-4f2d-98b4-adab8d6178d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    support itemsets\n",
              "0  0.044776      (A)\n",
              "1  0.044776      (B)\n",
              "2  0.044776      (C)\n",
              "3  0.059701      (F)\n",
              "4  0.074627      (G)"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b313b6f8-1661-4df8-bd56-9d50cb7a10a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>support</th>\n",
              "      <th>itemsets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.044776</td>\n",
              "      <td>(A)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.044776</td>\n",
              "      <td>(B)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.044776</td>\n",
              "      <td>(C)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.059701</td>\n",
              "      <td>(F)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.074627</td>\n",
              "      <td>(G)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b313b6f8-1661-4df8-bd56-9d50cb7a10a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b313b6f8-1661-4df8-bd56-9d50cb7a10a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b313b6f8-1661-4df8-bd56-9d50cb7a10a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import apriori\n",
        "\n",
        "min_support = 2/len(data.index)\n",
        "itemsets = apriori(data, \n",
        "                   min_support = min_support,\n",
        "                   max_len = 2,\n",
        "                   use_colnames = True)\n",
        "\n",
        "itemsets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "opK5Gc3uo-0d",
        "outputId": "fd6c8ec8-0a97-45e5-e9a4-7d764f248362"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  antecedents consequents  antecedent support  consequent support   support  \\\n",
              "0           N           T            0.089552            0.044776  0.044776   \n",
              "1           T           N            0.044776            0.089552  0.044776   \n",
              "\n",
              "   confidence       lift  leverage  conviction  \n",
              "0         0.5  11.166667  0.040766    1.910448  \n",
              "1         1.0  11.166667  0.040766         inf  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03880c62-a0dc-4bac-b022-83d2cbdd501f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>antecedents</th>\n",
              "      <th>consequents</th>\n",
              "      <th>antecedent support</th>\n",
              "      <th>consequent support</th>\n",
              "      <th>support</th>\n",
              "      <th>confidence</th>\n",
              "      <th>lift</th>\n",
              "      <th>leverage</th>\n",
              "      <th>conviction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>0.089552</td>\n",
              "      <td>0.044776</td>\n",
              "      <td>0.044776</td>\n",
              "      <td>0.5</td>\n",
              "      <td>11.166667</td>\n",
              "      <td>0.040766</td>\n",
              "      <td>1.910448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T</td>\n",
              "      <td>N</td>\n",
              "      <td>0.044776</td>\n",
              "      <td>0.089552</td>\n",
              "      <td>0.044776</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.166667</td>\n",
              "      <td>0.040766</td>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03880c62-a0dc-4bac-b022-83d2cbdd501f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03880c62-a0dc-4bac-b022-83d2cbdd501f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03880c62-a0dc-4bac-b022-83d2cbdd501f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "rules = association_rules(itemsets, min_threshold=min_support)\n",
        "\n",
        "rules[\"antecedents\"] = rules[\"antecedents\"].apply(lambda x: list(x)[0])\n",
        "rules[\"consequents\"] = rules[\"consequents\"].apply(lambda x: list(x)[0])\n",
        "\n",
        "rules.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "dOQON4DZpsRc",
        "outputId": "c2e83cce-77ca-4fd0-e48a-1296a3992785"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  antecedents consequents\n",
              "0           N           T\n",
              "1           T           N"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8204cfa-1d69-4b08-a6c6-ac27ec5c544f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>antecedents</th>\n",
              "      <th>consequents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8204cfa-1d69-4b08-a6c6-ac27ec5c544f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8204cfa-1d69-4b08-a6c6-ac27ec5c544f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8204cfa-1d69-4b08-a6c6-ac27ec5c544f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "rels = rules[rules['lift'] > 1]\n",
        "rels = rels[['antecedents', 'consequents']]\n",
        "\n",
        "rels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLWZ2mABqUx5",
        "outputId": "094e870f-6802-4a9a-f4ae-3b510752c5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.32)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting owlready2\n",
            "  Downloading Owlready2-0.39.tar.gz (25.5 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25.5 MB 83.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: owlready2\n",
            "  Building wheel for owlready2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for owlready2: filename=Owlready2-0.39-cp37-cp37m-linux_x86_64.whl size=22132075 sha256=6af64c91b04bfd94b93ac5e9f8e11d43bb87961ca83b9125a8b909fa4fdb316a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/5b/fc/da1e42a17f22cd62bfb170f847a3fb541a7f628858ad3595ec\n",
            "Successfully built owlready2\n",
            "Installing collected packages: owlready2\n",
            "Successfully installed owlready2-0.39\n"
          ]
        }
      ],
      "source": [
        "!pip install Cython\n",
        "!pip install owlready2\n",
        "from owlready2 import *\n",
        "\n",
        "onto = get_ontology('http://onto.owl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBDZG1jBq4xr"
      },
      "outputs": [],
      "source": [
        "import types\n",
        "\n",
        "with onto:\n",
        "  onto_cl = types.new_class('Piece', (Thing,))\n",
        "  for i, cl in enumerate(classes.values()):\n",
        "    inst = onto_cl(f'piece_{i}')\n",
        "    inst.label = cl\n",
        "\n",
        "onto.save(\"/content/onto.owl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWCPDblwrZYa"
      },
      "outputs": [],
      "source": [
        "with onto:\n",
        "  types.new_class('isAssociatedWith', (ObjectProperty, TransitiveProperty))\n",
        "  for index, rel in rels.iterrows():\n",
        "    onto_ant = onto.search_one(label=rel['antecedents'])\n",
        "    onto_con = onto.search_one(label=rel['consequents'])\n",
        "    onto_ant.isAssociatedWith.append(onto_con)\n",
        "    \n",
        "onto.save(\"/content/onto.owl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsyvVxLer0RF",
        "outputId": "c2de0f15-0d28-4772-f168-626bb7b0d3b1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "* Owlready2 * Running Pellet...\n",
            "    java -Xmx2000M -cp /usr/local/lib/python3.7/dist-packages/owlready2/pellet/slf4j-log4j12-1.6.4.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/xercesImpl-2.10.0.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/jena-tdb-0.10.0.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/jena-arq-2.10.0.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/httpclient-4.2.3.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/httpcore-4.2.2.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/antlr-3.2.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/commons-codec-1.6.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/xml-apis-1.4.01.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/slf4j-api-1.6.4.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/pellet-2.3.1.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/log4j-1.2.16.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/jena-core-2.10.0.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/jgrapht-jdk1.5.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/aterm-java-1.6.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/jcl-over-slf4j-1.6.4.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/jena-iri-0.9.5.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/owlapi-distribution-3.4.3-bin.jar:/usr/local/lib/python3.7/dist-packages/owlready2/pellet/antlr-runtime-3.2.jar pellet.Pellet realize --loader Jena --input-format N-Triples --infer-prop-values --ignore-imports /tmp/tmp5z4ng3wr\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Owlready * Adding relation onto.piece_19 isAssociatedWith onto.piece_19\n",
            "* Owlready * Adding relation onto.piece_13 isAssociatedWith onto.piece_13\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "* Owlready2 * Pellet took 1.6409428119659424 seconds\n",
            "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
          ]
        }
      ],
      "source": [
        "with onto:\n",
        "  sync_reasoner_pellet(infer_property_values = True)\n",
        "\n",
        "onto.save('onto_reasonde.owl', format = 'ntriples')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}